{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9beb44af",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Need to use Neural Network since its a complex non-linear relationship: Multilayer Perceptron (MLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d73cb20c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import os\n",
    "import sklearn as sk\n",
    "import random\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e8f49d9-b0f5-4840-ac85-763d4d234157",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e1ac8a0-a795-4243-a1f3-184c3e9eb4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b5fc675-0bfb-49b5-80d0-6341a3b0ef3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow import keras\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afebb096-7242-4fe7-981d-72bdf7314ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import databse\n",
    "\n",
    "# df = pd.read_csv('../data/raw/Elite_Sports_Cars_in_Data.csv')\n",
    "df = pd.read_csv('../data/raw/5000_car_dataset_TRANSMISSION_FIXED_FINAL.csv')\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6c42868-f9e8-4e91-a91a-80016d6a6f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Brand               5000 non-null   object \n",
      " 1   Model               5000 non-null   object \n",
      " 2   Year                5000 non-null   int64  \n",
      " 3   Horsepower          5000 non-null   int64  \n",
      " 4   Engine_Size         5000 non-null   float64\n",
      " 5   Weight              5000 non-null   int64  \n",
      " 6   Torque              5000 non-null   int64  \n",
      " 7   Acceleration_0_100  5000 non-null   float64\n",
      " 8   Power_Weight        5000 non-null   float64\n",
      " 9   Torque_Weight       5000 non-null   float64\n",
      " 10  Drivetrain          5000 non-null   object \n",
      " 11  Transmission        5000 non-null   object \n",
      "dtypes: float64(4), int64(4), object(4)\n",
      "memory usage: 468.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7853b588-a2fb-4826-a2b4-510ef33ef923",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Power_Weight\"] = df[\"Horsepower\"] / df[\"Weight\"]\n",
    "df[\"Torque_Weight\"] = df[\"Torque\"] / df[\"Weight\"]\n",
    "# df[\"Hp_liter\"] = df[\"Horsepower\"] / df[\"Engine_Size\"]\n",
    "\n",
    "# df[\"Car_Age\"] = 2025 - df[\"Year\"] -> turned to be redundant, introduce noise\n",
    "# df[\"Mileage_Per_Year\"] = df[\"Mileage\"] / df[\"Car_Age\"].replace(0, 1) -> turned to be redundant, introduce noise\n",
    "# df[\"Speed_Efficiency\"] = df[\"Top_Speed\"] / df[\"Horsepower\"] -> turned to be redundant, introduce noise\n",
    "\n",
    "# One-hot encode categorical features we need.\n",
    "df_encoded = pd.get_dummies(\n",
    "    df, \n",
    "    columns=['Drivetrain', 'Transmission'],\n",
    "    drop_first=True,\n",
    "    dtype=int\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02725300-947f-4339-a4b3-6747c895c015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Brand               5000 non-null   object \n",
      " 1   Model               5000 non-null   object \n",
      " 2   Year                5000 non-null   int64  \n",
      " 3   Horsepower          5000 non-null   int64  \n",
      " 4   Engine_Size         5000 non-null   float64\n",
      " 5   Weight              5000 non-null   int64  \n",
      " 6   Torque              5000 non-null   int64  \n",
      " 7   Acceleration_0_100  5000 non-null   float64\n",
      " 8   Power_Weight        5000 non-null   float64\n",
      " 9   Torque_Weight       5000 non-null   float64\n",
      " 10  Drivetrain_RWD      5000 non-null   int64  \n",
      " 11  Transmission_DCT    5000 non-null   int64  \n",
      "dtypes: float64(4), int64(6), object(2)\n",
      "memory usage: 468.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#df encoded shoudl not have drivetrain and transmission, but instead have the new ones \n",
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e8b6bcf-8646-4394-93f8-a2b584614906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in df_encoded:\n",
      "['Brand', 'Model', 'Year', 'Horsepower', 'Engine_Size', 'Weight', 'Torque', 'Acceleration_0_100', 'Power_Weight', 'Torque_Weight', 'Drivetrain_RWD', 'Transmission_DCT']\n",
      "\n",
      "\n",
      "Chosen Features:\n",
      "['Year', 'Horsepower', 'Engine_Size', 'Torque', 'Power_Weight', 'Torque_Weight', 'Weight', 'Drivetrain_RWD', 'Transmission_DCT']\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Select features + target\n",
    "\n",
    "Numerical_features = [\n",
    "    \"Year\", \n",
    "    \"Horsepower\", \n",
    "    \"Engine_Size\", \n",
    "    \"Torque\",\n",
    "    \"Power_Weight\", \n",
    "    \"Torque_Weight\",\n",
    "    \"Weight\",\n",
    "    # \"Hp_liter\"\n",
    "    #adding transmission, drivtrain, fuel type, modification to see its effect. DONe\n",
    "    #need encoding and one hot as well as droping redundancies for colinearity   \n",
    "]\n",
    "\n",
    "Binary_features = [\n",
    "    # 'Drivetrain_AWD', # zero because of drop first coloumn.\n",
    "    'Drivetrain_RWD', # 1\n",
    "    'Transmission_DCT',# 1\n",
    "    # 'Transmission_Auto' # zero because of drop first coloumn.\n",
    "]\n",
    "\n",
    "\n",
    "#combine the feature\n",
    "features = Numerical_features + Binary_features\n",
    "\n",
    "\n",
    "X = df_encoded[features].values\n",
    "y = df_encoded[\"Acceleration_0_100\"].values\n",
    "\n",
    "print(\"Columns in df_encoded:\")\n",
    "print(df_encoded.columns.tolist())\n",
    "print(\"\\n\")\n",
    "print(\"Chosen Features:\")\n",
    "print(features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5233a55-4c85-4a03-b6a8-0f3d9e1fc077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Train/Test split\n",
    "# -----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, \n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d32ec310-0ff3-4087-96a8-14d9cf8b843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up separation for scaling issue\n",
    "#get index of the numerical and binary features\n",
    "numerical_indexes = [features.index(f) for f in Numerical_features]\n",
    "binary_indexes = [features.index(f) for f in Binary_features]\n",
    "\n",
    "# separate the training set into numeric and binary so we can only scale the numeric and then add it back\n",
    "X_train_numerical= X_train[:,numerical_indexes]\n",
    "X_train_binary = X_train[:,binary_indexes]\n",
    "\n",
    "X_test_numerical= X_test[:,numerical_indexes]\n",
    "X_test_binary = X_test[:,binary_indexes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "230dc5fb-3861-4689-b033-d1e55bb5119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Scaling / normalaization so no value dominates any other value. \n",
    "# -----------------------------\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# now we take the separeted numerics and scale them\n",
    "\n",
    "X_train_scaled_numerical = scaler.fit_transform(X_train_numerical)\n",
    "X_test_scaled_numercial  = scaler.transform(X_test_numerical)\n",
    "\n",
    "# Now we take the scalred numerics and concatinate them with the binary to make the main train and test set.\n",
    "\n",
    "X_train = np.concatenate([X_train_scaled_numerical,X_train_binary], axis = 1 )\n",
    "\n",
    "X_test = np.concatenate([X_test_scaled_numercial,X_test_binary], axis = 1 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d83b33-fb47-485a-a3a7-f34f9ff6b3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab77925-baee-4048-a7b5-798a9b845362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b8c925-63ca-4768-b402-31e4732d237f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07093bf0-85a2-45d4-9239-5efc486a6272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 15:44:53.985566: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4 Max\n",
      "2025-12-02 15:44:53.985614: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 36.00 GB\n",
      "2025-12-02 15:44:53.985620: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 13.50 GB\n",
      "2025-12-02 15:44:53.985641: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-12-02 15:44:53.985653: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# 6. Build Neural Network\n",
    "# -----------------------------\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)), \n",
    "    \n",
    "    Dense(64, activation='relu'), # changed to 128 since we have more features now.\n",
    "    Dropout(0.1),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "\n",
    "    Dense(32, activation='relu'),\n",
    "\n",
    "    Dense(1)  # output layer for regression\n",
    "])\n",
    "#added momentum since we kept detecting oscillation\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.00005,\n",
    "                                    momentum=0.9,\n",
    "                                    clipnorm=1.0),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fe1f87-d4e6-4016-a1cb-dea88ed3a179",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5e70bba-e3fa-4abc-82a7-8b961fe88620",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=20,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cd04c3-299d-494e-bb14-baa37853e37b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58e367fe-736f-4f98-a22b-d52ba92bd1ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 15:44:58.074238: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 10.2923 - mae: 3.0765 - val_loss: 9.5910 - val_mae: 2.9915\n",
      "Epoch 2/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.7372 - mae: 2.9945 - val_loss: 8.9622 - val_mae: 2.8940\n",
      "Epoch 3/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.0983 - mae: 2.8945 - val_loss: 8.3472 - val_mae: 2.7939\n",
      "Epoch 4/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.4624 - mae: 2.7893 - val_loss: 7.7568 - val_mae: 2.6927\n",
      "Epoch 5/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.9630 - mae: 2.7022 - val_loss: 7.1914 - val_mae: 2.5905\n",
      "Epoch 6/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2677 - mae: 2.5749 - val_loss: 6.6509 - val_mae: 2.4871\n",
      "Epoch 7/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7548 - mae: 2.4758 - val_loss: 6.1356 - val_mae: 2.3826\n",
      "Epoch 8/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2575 - mae: 2.3744 - val_loss: 5.6452 - val_mae: 2.2768\n",
      "Epoch 9/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7093 - mae: 2.2522 - val_loss: 5.1797 - val_mae: 2.1697\n",
      "Epoch 10/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2283 - mae: 2.1377 - val_loss: 4.7388 - val_mae: 2.0612\n",
      "Epoch 11/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8175 - mae: 2.0333 - val_loss: 4.3242 - val_mae: 1.9517\n",
      "Epoch 12/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3659 - mae: 1.9188 - val_loss: 3.9359 - val_mae: 1.8410\n",
      "Epoch 13/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9898 - mae: 1.8041 - val_loss: 3.5727 - val_mae: 1.7301\n",
      "Epoch 14/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7040 - mae: 1.7112 - val_loss: 3.2347 - val_mae: 1.6188\n",
      "Epoch 15/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3205 - mae: 1.5862 - val_loss: 2.9204 - val_mae: 1.5081\n",
      "Epoch 16/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.0012 - mae: 1.4762 - val_loss: 2.6317 - val_mae: 1.4001\n",
      "Epoch 17/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7011 - mae: 1.3625 - val_loss: 2.3665 - val_mae: 1.2950\n",
      "Epoch 18/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4853 - mae: 1.2746 - val_loss: 2.1232 - val_mae: 1.1937\n",
      "Epoch 19/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.2560 - mae: 1.1889 - val_loss: 1.9020 - val_mae: 1.0983\n",
      "Epoch 20/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0254 - mae: 1.1120 - val_loss: 1.7035 - val_mae: 1.0127\n",
      "Epoch 21/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.8857 - mae: 1.0544 - val_loss: 1.5233 - val_mae: 0.9410\n",
      "Epoch 22/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6528 - mae: 0.9782 - val_loss: 1.3622 - val_mae: 0.8814\n",
      "Epoch 23/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5673 - mae: 0.9497 - val_loss: 1.2204 - val_mae: 0.8321\n",
      "Epoch 24/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4570 - mae: 0.9061 - val_loss: 1.0947 - val_mae: 0.7912\n",
      "Epoch 25/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3292 - mae: 0.8754 - val_loss: 0.9859 - val_mae: 0.7562\n",
      "Epoch 26/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2020 - mae: 0.8230 - val_loss: 0.8904 - val_mae: 0.7248\n",
      "Epoch 27/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0995 - mae: 0.8008 - val_loss: 0.8100 - val_mae: 0.6961\n",
      "Epoch 28/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0419 - mae: 0.7810 - val_loss: 0.7435 - val_mae: 0.6704\n",
      "Epoch 29/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9489 - mae: 0.7459 - val_loss: 0.6854 - val_mae: 0.6461\n",
      "Epoch 30/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9394 - mae: 0.7432 - val_loss: 0.6358 - val_mae: 0.6232\n",
      "Epoch 31/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8934 - mae: 0.7242 - val_loss: 0.5955 - val_mae: 0.6026\n",
      "Epoch 32/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8711 - mae: 0.7180 - val_loss: 0.5616 - val_mae: 0.5839\n",
      "Epoch 33/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8111 - mae: 0.6964 - val_loss: 0.5331 - val_mae: 0.5670\n",
      "Epoch 34/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.7860 - mae: 0.6830 - val_loss: 0.5105 - val_mae: 0.5527\n",
      "Epoch 35/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8073 - mae: 0.6878 - val_loss: 0.4884 - val_mae: 0.5388\n",
      "Epoch 36/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.7720 - mae: 0.6699 - val_loss: 0.4686 - val_mae: 0.5266\n",
      "Epoch 37/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.7562 - mae: 0.6645 - val_loss: 0.4538 - val_mae: 0.5171\n",
      "Epoch 38/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.7193 - mae: 0.6549 - val_loss: 0.4405 - val_mae: 0.5085\n",
      "Epoch 39/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.7343 - mae: 0.6619 - val_loss: 0.4291 - val_mae: 0.5012\n",
      "Epoch 40/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.7547 - mae: 0.6657 - val_loss: 0.4198 - val_mae: 0.4950\n",
      "Epoch 41/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7038 - mae: 0.6442 - val_loss: 0.4072 - val_mae: 0.4870\n",
      "Epoch 42/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6832 - mae: 0.6352 - val_loss: 0.3979 - val_mae: 0.4811\n",
      "Epoch 43/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7045 - mae: 0.6398 - val_loss: 0.3858 - val_mae: 0.4738\n",
      "Epoch 44/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6946 - mae: 0.6344 - val_loss: 0.3767 - val_mae: 0.4680\n",
      "Epoch 45/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6581 - mae: 0.6192 - val_loss: 0.3688 - val_mae: 0.4627\n",
      "Epoch 46/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6828 - mae: 0.6286 - val_loss: 0.3632 - val_mae: 0.4583\n",
      "Epoch 47/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6665 - mae: 0.6198 - val_loss: 0.3564 - val_mae: 0.4536\n",
      "Epoch 48/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6466 - mae: 0.6163 - val_loss: 0.3509 - val_mae: 0.4495\n",
      "Epoch 49/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6600 - mae: 0.6141 - val_loss: 0.3429 - val_mae: 0.4444\n",
      "Epoch 50/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5864 - mae: 0.5873 - val_loss: 0.3369 - val_mae: 0.4401\n",
      "Epoch 51/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6472 - mae: 0.6118 - val_loss: 0.3321 - val_mae: 0.4364\n",
      "Epoch 52/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6096 - mae: 0.5935 - val_loss: 0.3243 - val_mae: 0.4314\n",
      "Epoch 53/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6335 - mae: 0.6047 - val_loss: 0.3180 - val_mae: 0.4274\n",
      "Epoch 54/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6394 - mae: 0.6081 - val_loss: 0.3139 - val_mae: 0.4240\n",
      "Epoch 55/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6037 - mae: 0.5914 - val_loss: 0.3083 - val_mae: 0.4201\n",
      "Epoch 56/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6390 - mae: 0.6046 - val_loss: 0.3027 - val_mae: 0.4164\n",
      "Epoch 57/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6059 - mae: 0.5961 - val_loss: 0.2994 - val_mae: 0.4133\n",
      "Epoch 58/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5969 - mae: 0.5871 - val_loss: 0.2946 - val_mae: 0.4098\n",
      "Epoch 59/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6155 - mae: 0.5873 - val_loss: 0.2901 - val_mae: 0.4065\n",
      "Epoch 60/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5897 - mae: 0.5841 - val_loss: 0.2861 - val_mae: 0.4034\n",
      "Epoch 61/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5851 - mae: 0.5823 - val_loss: 0.2817 - val_mae: 0.4002\n",
      "Epoch 62/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6274 - mae: 0.5948 - val_loss: 0.2767 - val_mae: 0.3969\n",
      "Epoch 63/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6044 - mae: 0.5836 - val_loss: 0.2727 - val_mae: 0.3940\n",
      "Epoch 64/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5618 - mae: 0.5681 - val_loss: 0.2677 - val_mae: 0.3906\n",
      "Epoch 65/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5690 - mae: 0.5649 - val_loss: 0.2644 - val_mae: 0.3878\n",
      "Epoch 66/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5943 - mae: 0.5799 - val_loss: 0.2603 - val_mae: 0.3849\n",
      "Epoch 67/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5723 - mae: 0.5649 - val_loss: 0.2580 - val_mae: 0.3827\n",
      "Epoch 68/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5243 - mae: 0.5465 - val_loss: 0.2569 - val_mae: 0.3815\n",
      "Epoch 69/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5672 - mae: 0.5598 - val_loss: 0.2563 - val_mae: 0.3809\n",
      "Epoch 70/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5913 - mae: 0.5763 - val_loss: 0.2525 - val_mae: 0.3779\n",
      "Epoch 71/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5368 - mae: 0.5499 - val_loss: 0.2477 - val_mae: 0.3741\n",
      "Epoch 72/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6097 - mae: 0.5765 - val_loss: 0.2437 - val_mae: 0.3708\n",
      "Epoch 73/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5964 - mae: 0.5737 - val_loss: 0.2422 - val_mae: 0.3698\n",
      "Epoch 74/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5500 - mae: 0.5560 - val_loss: 0.2404 - val_mae: 0.3682\n",
      "Epoch 75/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5517 - mae: 0.5552 - val_loss: 0.2381 - val_mae: 0.3665\n",
      "Epoch 76/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5732 - mae: 0.5622 - val_loss: 0.2351 - val_mae: 0.3642\n",
      "Epoch 77/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5740 - mae: 0.5641 - val_loss: 0.2307 - val_mae: 0.3603\n",
      "Epoch 78/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5625 - mae: 0.5602 - val_loss: 0.2284 - val_mae: 0.3585\n",
      "Epoch 79/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5957 - mae: 0.5718 - val_loss: 0.2256 - val_mae: 0.3560\n",
      "Epoch 80/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5235 - mae: 0.5462 - val_loss: 0.2246 - val_mae: 0.3555\n",
      "Epoch 81/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5337 - mae: 0.5471 - val_loss: 0.2239 - val_mae: 0.3551\n",
      "Epoch 82/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5453 - mae: 0.5526 - val_loss: 0.2213 - val_mae: 0.3527\n",
      "Epoch 83/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5671 - mae: 0.5608 - val_loss: 0.2200 - val_mae: 0.3520\n",
      "Epoch 84/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5620 - mae: 0.5564 - val_loss: 0.2169 - val_mae: 0.3489\n",
      "Epoch 85/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5338 - mae: 0.5467 - val_loss: 0.2143 - val_mae: 0.3461\n",
      "Epoch 86/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5506 - mae: 0.5530 - val_loss: 0.2138 - val_mae: 0.3466\n",
      "Epoch 87/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5401 - mae: 0.5492 - val_loss: 0.2121 - val_mae: 0.3452\n",
      "Epoch 88/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5288 - mae: 0.5382 - val_loss: 0.2118 - val_mae: 0.3456\n",
      "Epoch 89/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5500 - mae: 0.5451 - val_loss: 0.2084 - val_mae: 0.3419\n",
      "Epoch 90/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5101 - mae: 0.5319 - val_loss: 0.2067 - val_mae: 0.3403\n",
      "Epoch 91/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5453 - mae: 0.5449 - val_loss: 0.2056 - val_mae: 0.3400\n",
      "Epoch 92/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5292 - mae: 0.5421 - val_loss: 0.2034 - val_mae: 0.3378\n",
      "Epoch 93/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5312 - mae: 0.5399 - val_loss: 0.2023 - val_mae: 0.3371\n",
      "Epoch 94/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5304 - mae: 0.5359 - val_loss: 0.2028 - val_mae: 0.3384\n",
      "Epoch 95/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5095 - mae: 0.5286 - val_loss: 0.1992 - val_mae: 0.3343\n",
      "Epoch 96/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5166 - mae: 0.5348 - val_loss: 0.1972 - val_mae: 0.3324\n",
      "Epoch 97/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4983 - mae: 0.5263 - val_loss: 0.1965 - val_mae: 0.3321\n",
      "Epoch 98/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5076 - mae: 0.5297 - val_loss: 0.1951 - val_mae: 0.3308\n",
      "Epoch 99/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5458 - mae: 0.5472 - val_loss: 0.1952 - val_mae: 0.3318\n",
      "Epoch 100/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5343 - mae: 0.5426 - val_loss: 0.1932 - val_mae: 0.3300\n",
      "Epoch 101/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5447 - mae: 0.5444 - val_loss: 0.1929 - val_mae: 0.3303\n",
      "Epoch 102/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5467 - mae: 0.5438 - val_loss: 0.1931 - val_mae: 0.3313\n",
      "Epoch 103/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5415 - mae: 0.5412 - val_loss: 0.1896 - val_mae: 0.3269\n",
      "Epoch 104/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5252 - mae: 0.5385 - val_loss: 0.1884 - val_mae: 0.3254\n",
      "Epoch 105/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5481 - mae: 0.5460 - val_loss: 0.1878 - val_mae: 0.3256\n",
      "Epoch 106/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5212 - mae: 0.5404 - val_loss: 0.1870 - val_mae: 0.3249\n",
      "Epoch 107/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5291 - mae: 0.5319 - val_loss: 0.1862 - val_mae: 0.3242\n",
      "Epoch 108/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5311 - mae: 0.5350 - val_loss: 0.1872 - val_mae: 0.3262\n",
      "Epoch 109/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5265 - mae: 0.5365 - val_loss: 0.1848 - val_mae: 0.3232\n",
      "Epoch 110/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4814 - mae: 0.5123 - val_loss: 0.1842 - val_mae: 0.3230\n",
      "Epoch 111/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5354 - mae: 0.5435 - val_loss: 0.1838 - val_mae: 0.3232\n",
      "Epoch 112/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5379 - mae: 0.5375 - val_loss: 0.1831 - val_mae: 0.3227\n",
      "Epoch 113/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5057 - mae: 0.5275 - val_loss: 0.1806 - val_mae: 0.3180\n",
      "Epoch 114/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5033 - mae: 0.5291 - val_loss: 0.1800 - val_mae: 0.3182\n",
      "Epoch 115/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5275 - mae: 0.5254 - val_loss: 0.1797 - val_mae: 0.3187\n",
      "Epoch 116/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5307 - mae: 0.5302 - val_loss: 0.1787 - val_mae: 0.3164\n",
      "Epoch 117/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5219 - mae: 0.5309 - val_loss: 0.1785 - val_mae: 0.3175\n",
      "Epoch 118/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4987 - mae: 0.5128 - val_loss: 0.1773 - val_mae: 0.3150\n",
      "Epoch 119/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5170 - mae: 0.5237 - val_loss: 0.1775 - val_mae: 0.3175\n",
      "Epoch 120/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5307 - mae: 0.5368 - val_loss: 0.1764 - val_mae: 0.3160\n",
      "Epoch 121/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5014 - mae: 0.5215 - val_loss: 0.1761 - val_mae: 0.3156\n",
      "Epoch 122/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5153 - mae: 0.5280 - val_loss: 0.1752 - val_mae: 0.3135\n",
      "Epoch 123/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5139 - mae: 0.5291 - val_loss: 0.1751 - val_mae: 0.3144\n",
      "Epoch 124/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5167 - mae: 0.5258 - val_loss: 0.1752 - val_mae: 0.3157\n",
      "Epoch 125/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5039 - mae: 0.5288 - val_loss: 0.1774 - val_mae: 0.3199\n",
      "Epoch 126/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5145 - mae: 0.5327 - val_loss: 0.1741 - val_mae: 0.3141\n",
      "Epoch 127/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5407 - mae: 0.5310 - val_loss: 0.1756 - val_mae: 0.3178\n",
      "Epoch 128/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5150 - mae: 0.5325 - val_loss: 0.1723 - val_mae: 0.3110\n",
      "Epoch 129/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5280 - mae: 0.5271 - val_loss: 0.1715 - val_mae: 0.3100\n",
      "Epoch 130/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4663 - mae: 0.5068 - val_loss: 0.1732 - val_mae: 0.3154\n",
      "Epoch 131/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5210 - mae: 0.5255 - val_loss: 0.1704 - val_mae: 0.3093\n",
      "Epoch 132/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5024 - mae: 0.5189 - val_loss: 0.1704 - val_mae: 0.3116\n",
      "Epoch 133/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4952 - mae: 0.5180 - val_loss: 0.1693 - val_mae: 0.3098\n",
      "Epoch 134/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4898 - mae: 0.5201 - val_loss: 0.1693 - val_mae: 0.3107\n",
      "Epoch 135/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5201 - mae: 0.5324 - val_loss: 0.1683 - val_mae: 0.3084\n",
      "Epoch 136/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4888 - mae: 0.5180 - val_loss: 0.1680 - val_mae: 0.3089\n",
      "Epoch 137/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5148 - mae: 0.5263 - val_loss: 0.1702 - val_mae: 0.3141\n",
      "Epoch 138/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4798 - mae: 0.5127 - val_loss: 0.1686 - val_mae: 0.3119\n",
      "Epoch 139/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4901 - mae: 0.5139 - val_loss: 0.1658 - val_mae: 0.3056\n",
      "Epoch 140/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4832 - mae: 0.5133 - val_loss: 0.1654 - val_mae: 0.3051\n",
      "Epoch 141/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4767 - mae: 0.5025 - val_loss: 0.1655 - val_mae: 0.3073\n",
      "Epoch 142/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5017 - mae: 0.5282 - val_loss: 0.1647 - val_mae: 0.3052\n",
      "Epoch 143/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5016 - mae: 0.5209 - val_loss: 0.1647 - val_mae: 0.3062\n",
      "Epoch 144/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4936 - mae: 0.5185 - val_loss: 0.1645 - val_mae: 0.3064\n",
      "Epoch 145/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4895 - mae: 0.5188 - val_loss: 0.1653 - val_mae: 0.3092\n",
      "Epoch 146/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4974 - mae: 0.5238 - val_loss: 0.1641 - val_mae: 0.3064\n",
      "Epoch 147/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4940 - mae: 0.5218 - val_loss: 0.1634 - val_mae: 0.3046\n",
      "Epoch 148/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5029 - mae: 0.5195 - val_loss: 0.1657 - val_mae: 0.3109\n",
      "Epoch 149/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4955 - mae: 0.5140 - val_loss: 0.1641 - val_mae: 0.3079\n",
      "Epoch 150/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5053 - mae: 0.5191 - val_loss: 0.1659 - val_mae: 0.3113\n",
      "Epoch 151/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5045 - mae: 0.5253 - val_loss: 0.1625 - val_mae: 0.3038\n",
      "Epoch 152/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5039 - mae: 0.5123 - val_loss: 0.1619 - val_mae: 0.3031\n",
      "Epoch 153/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4984 - mae: 0.5210 - val_loss: 0.1643 - val_mae: 0.3098\n",
      "Epoch 154/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4926 - mae: 0.5177 - val_loss: 0.1613 - val_mae: 0.3024\n",
      "Epoch 155/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4787 - mae: 0.5127 - val_loss: 0.1612 - val_mae: 0.3025\n",
      "Epoch 156/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4576 - mae: 0.5012 - val_loss: 0.1630 - val_mae: 0.3080\n",
      "Epoch 157/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5045 - mae: 0.5236 - val_loss: 0.1610 - val_mae: 0.3026\n",
      "Epoch 158/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4927 - mae: 0.5134 - val_loss: 0.1615 - val_mae: 0.3004\n",
      "Epoch 159/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5296 - mae: 0.5281 - val_loss: 0.1605 - val_mae: 0.3015\n",
      "Epoch 160/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4904 - mae: 0.5172 - val_loss: 0.1602 - val_mae: 0.3028\n",
      "Epoch 161/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5454 - mae: 0.5313 - val_loss: 0.1598 - val_mae: 0.3022\n",
      "Epoch 162/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4938 - mae: 0.5115 - val_loss: 0.1594 - val_mae: 0.3006\n",
      "Epoch 163/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4840 - mae: 0.5161 - val_loss: 0.1594 - val_mae: 0.3024\n",
      "Epoch 164/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5132 - mae: 0.5260 - val_loss: 0.1592 - val_mae: 0.3025\n",
      "Epoch 165/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4989 - mae: 0.5120 - val_loss: 0.1588 - val_mae: 0.2999\n",
      "Epoch 166/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4979 - mae: 0.5148 - val_loss: 0.1590 - val_mae: 0.3032\n",
      "Epoch 167/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5102 - mae: 0.5192 - val_loss: 0.1584 - val_mae: 0.3009\n",
      "Epoch 168/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4683 - mae: 0.5037 - val_loss: 0.1587 - val_mae: 0.3032\n",
      "Epoch 169/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4695 - mae: 0.5059 - val_loss: 0.1587 - val_mae: 0.3034\n",
      "Epoch 170/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4845 - mae: 0.5131 - val_loss: 0.1602 - val_mae: 0.3067\n",
      "Epoch 171/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5008 - mae: 0.5200 - val_loss: 0.1582 - val_mae: 0.3031\n",
      "Epoch 172/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4791 - mae: 0.5061 - val_loss: 0.1581 - val_mae: 0.3030\n",
      "Epoch 173/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4988 - mae: 0.5133 - val_loss: 0.1572 - val_mae: 0.2984\n",
      "Epoch 174/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4829 - mae: 0.5068 - val_loss: 0.1618 - val_mae: 0.3097\n",
      "Epoch 175/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4838 - mae: 0.5161 - val_loss: 0.1570 - val_mae: 0.3010\n",
      "Epoch 176/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4907 - mae: 0.5112 - val_loss: 0.1569 - val_mae: 0.3017\n",
      "Epoch 177/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4543 - mae: 0.5005 - val_loss: 0.1559 - val_mae: 0.2972\n",
      "Epoch 178/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5190 - mae: 0.5153 - val_loss: 0.1557 - val_mae: 0.2978\n",
      "Epoch 179/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4735 - mae: 0.4978 - val_loss: 0.1561 - val_mae: 0.2961\n",
      "Epoch 180/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4821 - mae: 0.5069 - val_loss: 0.1554 - val_mae: 0.2977\n",
      "Epoch 181/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5053 - mae: 0.5121 - val_loss: 0.1558 - val_mae: 0.2958\n",
      "Epoch 182/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4930 - mae: 0.5092 - val_loss: 0.1553 - val_mae: 0.2979\n",
      "Epoch 183/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4735 - mae: 0.5047 - val_loss: 0.1567 - val_mae: 0.3029\n",
      "Epoch 184/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4661 - mae: 0.5014 - val_loss: 0.1568 - val_mae: 0.3032\n",
      "Epoch 185/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4645 - mae: 0.4990 - val_loss: 0.1551 - val_mae: 0.2988\n",
      "Epoch 186/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4939 - mae: 0.5096 - val_loss: 0.1563 - val_mae: 0.3027\n",
      "Epoch 187/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4661 - mae: 0.4955 - val_loss: 0.1545 - val_mae: 0.2973\n",
      "Epoch 188/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4254 - mae: 0.4837 - val_loss: 0.1543 - val_mae: 0.2978\n",
      "Epoch 189/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4737 - mae: 0.5046 - val_loss: 0.1646 - val_mae: 0.3147\n",
      "Epoch 190/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4418 - mae: 0.4896 - val_loss: 0.1544 - val_mae: 0.2975\n",
      "Epoch 191/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4536 - mae: 0.4921 - val_loss: 0.1584 - val_mae: 0.3068\n",
      "Epoch 192/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4576 - mae: 0.4889 - val_loss: 0.1543 - val_mae: 0.2952\n",
      "Epoch 193/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4531 - mae: 0.4954 - val_loss: 0.1571 - val_mae: 0.3050\n",
      "Epoch 194/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4743 - mae: 0.5070 - val_loss: 0.1540 - val_mae: 0.2978\n",
      "Epoch 195/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4636 - mae: 0.5000 - val_loss: 0.1540 - val_mae: 0.2985\n",
      "Epoch 196/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4986 - mae: 0.5160 - val_loss: 0.1535 - val_mae: 0.2959\n",
      "Epoch 197/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4850 - mae: 0.5026 - val_loss: 0.1533 - val_mae: 0.2958\n",
      "Epoch 198/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4762 - mae: 0.4989 - val_loss: 0.1555 - val_mae: 0.3031\n",
      "Epoch 199/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4850 - mae: 0.5047 - val_loss: 0.1533 - val_mae: 0.2974\n",
      "Epoch 200/200\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4601 - mae: 0.5001 - val_loss: 0.1574 - val_mae: 0.3062\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=200,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop],\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08082f90-a95c-40f7-94cf-6798b7c5a326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c47f5802-95c7-43ef-969f-5d4ade58c26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/feature_info.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model for live prediction and later evaluation.\n",
    "\n",
    "model.save('../models/nn_zero_to_sixty.keras')\n",
    "\n",
    "\n",
    "joblib.dump(features, '../models/feature_names.pkl')\n",
    "\n",
    "\n",
    "joblib.dump(scaler, '../models/nn_scaler.pkl')\n",
    "\n",
    "\n",
    "\n",
    "# Save feature info for selective scaling\n",
    "feature_info = {\n",
    "    'numeric_features': Numerical_features,\n",
    "    'binary_features': Binary_features,\n",
    "    'numeric_indices': [features.index(f) for f in Numerical_features],\n",
    "    'binary_indices': [features.index(f) for f in Binary_features],\n",
    "    'total_features': len(features)\n",
    "}\n",
    "joblib.dump(feature_info, '../models/feature_info.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b9bdc3-2e0c-411d-998b-1d275f78abd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba510248-7dd3-474c-ae1b-b56594d3a79e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad1d5ef8-3f33-4a73-a99a-cf3717c82d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation with Acceleration_0_100:\n",
      "Year                     : -0.2972\n",
      "Horsepower               : -0.6023\n",
      "Engine_Size              : -0.0011\n",
      "Torque                   : -0.5895\n",
      "Power_Weight             : -0.7663\n",
      "Torque_Weight            : -0.7513\n",
      "Weight                   : +0.6614\n",
      "Drivetrain_RWD           : +0.0100\n",
      "Transmission_DCT         : -0.6011\n"
     ]
    }
   ],
   "source": [
    "# correlation with target\n",
    "print(\"Correlation with Acceleration_0_100:\")\n",
    "\n",
    "\n",
    "# Numeric features\n",
    "for feat in Numerical_features:\n",
    "    corr = df_encoded[feat].corr(df_encoded['Acceleration_0_100'])\n",
    "    print(f\"{feat:25s}: {corr:+.4f}\")\n",
    "\n",
    "# Binary features\n",
    "for feat in Binary_features:\n",
    "    corr = df_encoded[feat].corr(df_encoded['Acceleration_0_100'])\n",
    "    print(f\"{feat:25s}: {corr:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71c677db-b85d-4222-9cc4-b694677aa221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seems like they are being scaled, and that is why we are getting the same results as the 7-feature training model. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d13557c-5837-4ef6-8d6a-35c9c46494cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    '../models/nn_zero_to_sixty.keras',\n",
    "    compile=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e1dfe9b-745e-43c8-96d2-5e8039c141cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8614f8ea-3712-4b6f-9a8b-31a2bdaecc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c7536c7-747d-4c1c-8e32-ebdc84100675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1601 - mae: 0.3139\n",
      "Test Loss (MSE): 0.1601\n",
      "Test MAE: 0.3139\n",
      "Test RMSE: 0.4001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_results = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "test_loss = test_results[0]\n",
    "test_mae = test_results[1] \n",
    "\n",
    "print(f\"Test Loss (MSE): {test_loss:.4f}\")\n",
    "print(f\"Test MAE: {test_mae:.4f}\")\n",
    "print(f\"Test RMSE: {np.sqrt(test_loss):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f208c706-70b2-4c4a-aa41-fee219feccde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "025f8349-a67d-4c4f-b891-33a37177b5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run using: Year', 'Horsepower', 'Weight', 'Torque', 'Power_Weight', 'Torque_Weight', 'Transmission_DCT', 'Transmission_Auto'], \n",
    "#with drop first for encoded. \n",
    "\n",
    "# 32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1156 - mae: 0.2732\n",
    "# Test Loss (MSE): 0.1156\n",
    "# Test MAE: 0.2732\n",
    "# Test RMSE: 0.3400\n",
    "\n",
    "#run using: Year', 'Horsepower', 'Weight', 'Torque', 'Power_Weight', 'Torque_Weight', 'Transmission_DCT', 'Transmission_Auto'], \n",
    "#with drop first for encoded. \n",
    "\n",
    "# 32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1277 - mae: 0.2835\n",
    "# Test Loss (MSE): 0.1277\n",
    "# Test MAE: 0.2835\n",
    "# Test RMSE: 0.3574\n",
    "\n",
    "\n",
    "#run with ['Year', 'Horsepower', 'Weight', 'Torque', 'Power_Weight', 'Torque_Weight', 'Drivetrain_RWD', 'Transmission_DCT'],\n",
    "#   optimizer=keras.optimizers.SGD(learning_rate=0.00005, momentum=0.9),\n",
    "#  epochs=200,\n",
    "#     batch_size=128,\n",
    "#     validation_split=0.2,\n",
    "#     callbacks=[early_stop],\n",
    "#     shuffle=True\n",
    "# df_encoded = pd.get_dummies(\n",
    "#     df, \n",
    "#     columns=['Drivetrain', 'Transmission'],\n",
    "#     drop_first=True,\n",
    "#     dtype=int\n",
    "# )\n",
    "\n",
    "# 32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1447 - mae: 0.3001\n",
    "# Test Loss (MSE): 0.1447\n",
    "# Test MAE: 0.3001\n",
    "# Test RMSE: 0.3804\n",
    "# no snpike in graph.\n",
    "\n",
    "\n",
    "# was run with leanring rate reudction with gds, and using  adam  iwth the leanring rate wboth gave bad results. compared to what we had to this point\n",
    "\n",
    "\n",
    "\n",
    "# again we ran it and had these results\n",
    "\n",
    "# 32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1406 - mae: 0.2965\n",
    "# Test Loss (MSE): 0.1406\n",
    "# Test MAE: 0.2965?\n",
    "# Test RMSE: 0.3750\n",
    "\n",
    "\n",
    "# 32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1538 - mae: 0.3069\n",
    "# Test Loss (MSE): 0.1538\n",
    "# Test MAE: 0.3069\n",
    "# Test RMSE: 0.3921\n",
    "\n",
    "\n",
    "# 32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1641 - mae: 0.3179\n",
    "# Test Loss (MSE): 0.1641\n",
    "# Test MAE: 0.3179\n",
    "# Test RMSE: 0.4051\n",
    "\n",
    "\n",
    "#run with ['Year', 'Horsepower', 'Weight', 'Torque', 'Power_Weight', 'Engine_size', 'Torque_Weight', 'Drivetrain_RWD', 'Transmission_DCT'],\n",
    "#   optimizer=keras.optimizers.SGD(learning_rate=0.00005, momentum=0.9),\n",
    "#  epochs=200,\n",
    "#     batch_size=128,\n",
    "#     validation_split=0.2,\n",
    "#     callbacks=[early_stop],\n",
    "#     shuffle=True\n",
    "# df_encoded = pd.get_dummies(\n",
    "#     df, \n",
    "#     columns=['Drivetrain', 'Transmission'],\n",
    "#     drop_first=True,\n",
    "#     dtype=int\n",
    "# )\n",
    "\n",
    "# 32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1425 - mae: 0.3056\n",
    "# Test Loss (MSE): 0.1425\n",
    "# Test MAE: 0.3056\n",
    "# Test RMSE: 0.3776\n",
    "\n",
    "\n",
    "# 32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1374 - mae: 0.2912\n",
    "# Test Loss (MSE): 0.1374\n",
    "# Test MAE: 0.2912\n",
    "# Test RMSE: 0.3707\n",
    "\n",
    "\n",
    "# 32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1624 - mae: 0.3194\n",
    "# Test Loss (MSE): 0.1624\n",
    "# Test MAE: 0.3194\n",
    "# Test RMSE: 0.4029\n",
    "\n",
    "\n",
    "# 32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1385 - mae: 0.2991\n",
    "# Test Loss (MSE): 0.1385\n",
    "# Test MAE: 0.2991\n",
    "# Test RMSE: 0.3721\n",
    "\n",
    "\n",
    "# 32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.2327 - mae: 0.3677\n",
    "# Test Loss (MSE): 0.2327\n",
    "# Test MAE: 0.3677\n",
    "# Test RMSE: 0.4824\n",
    "# huge spike.\n",
    "# Epoch 116/200\n",
    "# 25/25 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - loss: 0.9798 - mae: 0.6941 - val_loss: 0.2287 - val_mae: 0.3622\n",
    "# Epoch 117/200\n",
    "# 25/25 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 17.1816 - mae: 2.1937 - val_loss: 17.7747 - val_mae: 3.3657\n",
    "# Epoch 118/200\n",
    "# 25/25 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 1049.5535 - mae: 19.8809 - val_loss: 83.2351 - val_mae: 7.3235\n",
    "# Epoch 119/200\n",
    "# 25/25 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 44.0157 - mae: 4.4439 - val_loss: 3.6105 - val_mae: 1.4323\n",
    "# Epoch 120/200\n",
    "# 25/25 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 3.9601 - mae: 1.4718 - val_loss: 2.1139 - val_mae: 1.0881\n",
    "# Epoch 121/200\n",
    "# 25/25 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 1.2827 - mae: 0.9040 - val_loss: 0.9825 - val_mae: 0.7630\n",
    "# Epoch 122/200\n",
    "# 25/25 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.9574 - mae: 0.7930 - val_loss: 0.6646 - val_mae: 0.7119\n",
    "# Epoch 123/200\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1367 - mae: 0.2972\n",
    "# Test Loss (MSE): 0.1367\n",
    "# Test MAE: 0.2972\n",
    "# Test RMSE: 0.3698\n",
    "\n",
    "\n",
    "# 32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1650 - mae: 0.3073\n",
    "# Test Loss (MSE): 0.1650\n",
    "# Test MAE: 0.3073\n",
    "# Test RMSE: 0.4062\n",
    "\n",
    "\n",
    "# 32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1372 - mae: 0.2931\n",
    "# Test Loss (MSE): 0.1372\n",
    "# Test MAE: 0.2931\n",
    "# Test RMSE: 0.3704\n",
    "\n",
    "# \"with weight.\"\n",
    "\n",
    "\n",
    "# 32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.1601 - mae: 0.3139\n",
    "# Test Loss (MSE): 0.1601\n",
    "# Test MAE: 0.3139\n",
    "# Test RMSE: 0.4001\n",
    "\n",
    "\n",
    "\n",
    "# without weight\n",
    "# 32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - loss: 0.1792 - mae: 0.3104\n",
    "# Test Loss (MSE): 0.1792\n",
    "# Test MAE: 0.3104\n",
    "# Test RMSE: 0.4233\n",
    "\n",
    "# 32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1582 - mae: 0.3091\n",
    "# Test Loss (MSE): 0.1582\n",
    "# Test MAE: 0.3091\n",
    "# Test RMSE: 0.3978\n",
    "\n",
    "# 32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1409 - mae: 0.2953\n",
    "# Test Loss (MSE): 0.1409\n",
    "# Test MAE: 0.2953\n",
    "# Test RMSE: 0.3754\n",
    "\n",
    "# anomaly \n",
    "# Test Loss (MSE): 10.4148\n",
    "# Test MAE: 3.1145\n",
    "# Test RMSE: 3.2272?\n",
    "\n",
    "\n",
    "# 32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.1601 - mae: 0.3139\n",
    "# Test Loss (MSE): 0.1601\n",
    "# Test MAE: 0.3139\n",
    "# Test RMSE: 0.4001\n",
    "\n",
    "\n",
    "# removing enginesize\n",
    "\n",
    "\n",
    "# 32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1323 - mae: 0.2888\n",
    "# Test Loss (MSE): 0.1323\n",
    "# Test MAE: 0.2888\n",
    "# Test RMSE: 0.3638\n",
    "\n",
    "# 32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1249 - mae: 0.2825\n",
    "# Test Loss (MSE): 0.1249\n",
    "# Test MAE: 0.2825\n",
    "# Test RMSE: 0.3535"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13394f5-def0-4e67-991d-f23338d53096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7938fc2-9866-43d5-a8b9-ac47220a590e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4037b3ab-d0ec-4b6d-93be-b19be43f963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1727cc2c-d137-4cb8-8e9c-174f80524050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
